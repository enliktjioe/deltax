{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import os\n",
    "import glob\n",
    "import sys\n",
    "import gc\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "module_path = os.path.abspath(os.path.join('..'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "\n",
    "from commons.configuration_manager import ConfigurationManager\n",
    "from src.learning.training.collector import Collector\n",
    "from src.learning.training.generator import GenFiles\n",
    "from src.learning.training.training_file_reader import TrainingFileReader\n",
    "from notebooks.notebook_commons import read_shifted_numerics_and_targets, read_stored_data_with_shifted_labels, create_memorized_dataset\n",
    "from src.utilities.transformer import Transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_genfile_folder(path):\n",
    "    if not os.path.isdir(path):\n",
    "        os.mkdir(path)\n",
    "    \n",
    "    old_genfiles = glob.glob(path + '*')\n",
    "    for old_genfile in old_genfiles:\n",
    "        os.remove(old_genfile)\n",
    "\n",
    "def plot_stuff(title, plot_elems, bins=None, figsize=(18, 10)):\n",
    "    fig=plt.figure(figsize=figsize)\n",
    "    plt.title(title)\n",
    "    #plt.ylabel('dunno')\n",
    "    plt.xlabel('Count')\n",
    "    \n",
    "    for plot_elem in plot_elems:\n",
    "        plt.hist(plot_elem['data'], bins=bins, **plot_elem['kwargs'])\n",
    "\n",
    "    plt.grid(axis='both')\n",
    "    plt.legend(loc='best')\n",
    "    plt.show()\n",
    "\n",
    "def half_max_thresh(counts: dict):\n",
    "    return int(np.mean(counts) +  (np.max(counts) - np.mean(counts)) // 2)\n",
    "\n",
    "def mean_thresh(counts: dict):\n",
    "    return int(np.mean(counts))\n",
    "\n",
    "def double_mean_thresh(counts: dict):\n",
    "    return int(2 * np.mean(counts))\n",
    "    \n",
    "def downsample_indexes(data_column, sample_threshold, sampling=None, bin_start=-1.0, bin_end=1.0, bin_size=0.01):\n",
    "    if sampling is None:\n",
    "        downsampling = np.ones(data_column.shape, dtype=int)\n",
    "    else:\n",
    "        downsampling = np.copy(sampling)\n",
    "    \n",
    "    bins = np.arange(bin_start, bin_end, bin_size)\n",
    "    indices = np.digitize(data_column, bins)\n",
    "    unique_bins, counts = np.unique(indices, return_counts=True)\n",
    "    sorted_counts = np.sort(counts)\n",
    "    \n",
    "    count_dict = dict(zip(unique_bins, counts))\n",
    "    threshold_count = sample_threshold(counts)\n",
    "    \n",
    "    for unique_bin, count in count_dict.items():\n",
    "        if count > threshold_count:\n",
    "            indexes = np.where(indices == unique_bin)[0]\n",
    "            to_del_indexes = np.random.choice(indexes, count - threshold_count, replace=False)\n",
    "            \n",
    "            downsampling[to_del_indexes] = 0\n",
    "    \n",
    "    return downsampling\n",
    "\n",
    "def upsample_indexes(data_column, sampling, sample_threshold, bin_start=-1.0, bin_end=1.0, bin_size=0.01):\n",
    "    upsample_multipliers = np.zeros(data_column.shape, dtype=int)\n",
    "    bins = np.arange(bin_start, bin_end, bin_size)\n",
    "    indices = np.digitize(data_column, bins)\n",
    "    \n",
    "    unique_bins, counts = np.unique(indices, return_counts=True)\n",
    "    count_dict = dict(zip(unique_bins, counts))\n",
    "    threshold_count = sample_threshold(counts)\n",
    "    \n",
    "    for i in range(0, upsample_multipliers.shape[0]):\n",
    "        count = count_dict[indices[i]]\n",
    "        if count >= threshold_count:\n",
    "            upsample_multipliers[i] = sampling[i]\n",
    "        else:\n",
    "            upsample_multipliers[i] = int(threshold_count / count)\n",
    "    \n",
    "    return upsample_multipliers\n",
    "\n",
    "\n",
    "# At current recording speed, 50 instances _should_ come up to about 5 seconds\n",
    "def sample_recovery_indexes(gear_column, sampling=None, count_to_crash=20, peek_limit=100):\n",
    "    if sampling is None:\n",
    "        recovery_sampling = np.ones(gear_column.shape, dtype=int)\n",
    "    else:\n",
    "        recovery_sampling = np.copy(sampling)\n",
    "    last_gear = None\n",
    "    \n",
    "    recovery_start = None\n",
    "    recovery_end = None\n",
    "    \n",
    "    for index, current_gear in enumerate(gear_column):\n",
    "        if last_gear is None:\n",
    "            last_gear = current_gear\n",
    "            continue\n",
    "        \n",
    "        if last_gear == 1 and current_gear == 0 and is_reversing_ahead(gear_column, index, peek_limit):\n",
    "            recovery_start = index\n",
    "        \n",
    "        if last_gear == 0 and current_gear == 1 and is_reversing_before(gear_column, index, peek_limit):\n",
    "            recovery_end = index\n",
    "        \n",
    "        if recovery_start is not None and recovery_end is not None:\n",
    "            recovery_sampling[recovery_start:recovery_end] = 1\n",
    "            \n",
    "            bad_driving_start = recovery_start - count_to_crash\n",
    "            if bad_driving_start >= 0:\n",
    "                recovery_sampling[bad_driving_start : recovery_start] = 0\n",
    "            else:\n",
    "                recovery_sampling[0 : recovery_start] = 0\n",
    "            \n",
    "            recovery_start = None\n",
    "            recovery_end = None\n",
    "        \n",
    "        last_gear = current_gear\n",
    "    return recovery_sampling\n",
    "\n",
    "\n",
    "def is_reversing_ahead(gear_column, index, peek_limit):\n",
    "    end_index = index + peek_limit\n",
    "    \n",
    "    if end_index >= gear_column.shape[0]:\n",
    "        end_index = gear_column.shape[0] - 1\n",
    "        \n",
    "    for i in range(index, end_index):\n",
    "        if gear_column[i] == -1:\n",
    "            return True\n",
    "        \n",
    "    return False\n",
    "\n",
    "\n",
    "def is_reversing_before(gear_column, index, peek_limit):\n",
    "    start_index = index - peek_limit\n",
    "    \n",
    "    if start_index < 0:\n",
    "        start_index = 0\n",
    "        \n",
    "    for i in range(index, start_index, -1):\n",
    "        if gear_column[i] == -1:\n",
    "            return True\n",
    "        \n",
    "    return False\n",
    "\n",
    "\n",
    "def store_sampling(new_sampling, path, filename, clean=False):\n",
    "    if os.path.isfile(path + filename):\n",
    "        if clean:\n",
    "            os.remove(glob.glob(path + filename)[0])\n",
    "            full_sampling = new_sampling\n",
    "        else:\n",
    "            stored_sampling = np.load(path + filename, allow_pickle=True)\n",
    "            full_sampling = np.concatenate((stored_sampling, new_sampling), axis=0)\n",
    "    else:\n",
    "        full_sampling = new_sampling\n",
    "    \n",
    "    np.save(path + filename, full_sampling)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate training partials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config_manager = ConfigurationManager()\n",
    "config = config_manager.config\n",
    "\n",
    "base_path = '../../training/'\n",
    "\n",
    "reader = TrainingFileReader(path_to_training=base_path + 'laps/')\n",
    "collector = Collector()\n",
    "\n",
    "filenames = [fn.split('.')[0] for fn in os.listdir(base_path + 'laps/') if fn.endswith('.avi')]\n",
    "#filenames = [fn.split('.')[0] for fn in os.listdir(base_path + 'laps/') if fn.endswith('.avi') and '_lap_' in fn]\n",
    "#filenames = ['archived_automatic_gear/' + fn.split('.')[0] for fn in os.listdir(base_path + 'laps/archived_automatic_gear/') if fn.endswith('.avi')]\n",
    "#filenames = filenames[:4]\n",
    "print(filenames)\n",
    "\n",
    "memory_variants = [(1, 1), (2, 1), (2, 2), (4, 1), (4, 2), (6, 1), (6, 2)]\n",
    "memory_variants = memory_variants[:1]\n",
    "augmentation = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create partials for memory variants\n",
    "\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator \n",
    "generator = ImageDataGenerator()\n",
    "\n",
    "total_diffs = {}\n",
    "\n",
    "for memory in tqdm(memory_variants):\n",
    "    total_diff = None\n",
    "    transformer = Transformer(config, memory)\n",
    "    \n",
    "    len_diff = (memory[0] - 1) * memory[1]\n",
    "    memory_string = 'n{}_m{}'.format(*memory)\n",
    "    \n",
    "    path = base_path + memory_string + '/'\n",
    "    clean_genfile_folder(path)\n",
    "    \n",
    "    tqdm.write('Writing n{}_m{} files.'.format(*memory))    \n",
    "    \n",
    "    for filename in tqdm(filenames):\n",
    "        mem_slice_frames = []\n",
    "        mem_slice_numerics = []\n",
    "        \n",
    "        existing_count = len([fn for fn in os.listdir(path) if fn.startswith('frame_')])\n",
    "        \n",
    "        numerics, diffs = read_shifted_numerics_and_targets(reader, filename, collector.numeric_columns(), collector.numeric_columns())\n",
    "        stored_i = 0\n",
    "        \n",
    "        for i, frame in reader.read_video_gen(filename + '.avi', diffs.shape[0]):\n",
    "            # Augmentation\n",
    "            if augmentation:\n",
    "                transform_params = {'brightness': np.random.uniform(0.4, 1.3)}    \n",
    "                frame = generator.apply_transform(frame, transform_params)\n",
    "            \n",
    "                #should_flip = np.random.uniform(0.0, 1.0) > 0.9\n",
    "                #if should_flip and memory[0] == 1:\n",
    "                #    transform_params['flip_horizontal'] = True\n",
    "                #    numerics[i, 1] *= -1.0\n",
    "                #    diffs[i, 1] *= -1.0\n",
    "            \n",
    "            mem_frame = transformer.session_frame_wide(frame, mem_slice_frames)\n",
    "            mem_numeric = transformer.session_numeric_np(numerics[i], mem_slice_numerics)\n",
    "            \n",
    "            if mem_frame is None or mem_numeric is None:\n",
    "                continue\n",
    "            \n",
    "            np.save(path + GenFiles.frame.format(memory_string, stored_i + existing_count), mem_frame)\n",
    "            np.save(path + GenFiles.numeric.format(memory_string, stored_i + existing_count), mem_numeric)\n",
    "            np.save(path + GenFiles.diff.format(memory_string, stored_i + existing_count), diffs[i])\n",
    "            stored_i += 1\n",
    "            \n",
    "        if total_diff is None:\n",
    "            total_diff = diffs[len_diff:].copy()\n",
    "        else:\n",
    "            total_diff = np.concatenate((total_diff, diffs[len_diff:].copy()))\n",
    "\n",
    "        gc.collect()\n",
    "        \n",
    "    total_diffs[memory_string] = total_diff"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate validation partials "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_reader = TrainingFileReader(path_to_training=base_path + 'validation_laps/')\n",
    "\n",
    "val_filenames = [fn.split('.')[0] for fn in os.listdir(base_path + 'validation_laps/') if fn.endswith('.avi') and 'validation' in fn]\n",
    "print(val_filenames)\n",
    "\n",
    "for memory in tqdm(memory_variants):\n",
    "    transformer = Transformer(config, memory)\n",
    "    \n",
    "    len_diff = (memory[0] - 1) * memory[1]\n",
    "    memory_string = 'n{}_m{}'.format(*memory)\n",
    "    \n",
    "    val_path = base_path + memory_string + '_val/'\n",
    "    clean_genfile_folder(val_path)\n",
    "    tqdm.write('Writing n{}_m{}_val files.'.format(*memory))    \n",
    "    \n",
    "    for filename in tqdm(val_filenames):\n",
    "        mem_slice_frames = []\n",
    "        mem_slice_numerics = []\n",
    "        \n",
    "        existing_count = len([fn for fn in os.listdir(val_path) if fn.startswith('frame_')])\n",
    "        \n",
    "        numerics, diffs = read_shifted_numerics_and_targets(val_reader, filename, collector.numeric_columns(), collector.numeric_columns())\n",
    "        stored_i = 0\n",
    "        \n",
    "        for i, frame in val_reader.read_video_gen(filename + '.avi', diffs.shape[0]):\n",
    "            mem_frame = transformer.session_frame_wide(frame, mem_slice_frames)\n",
    "            mem_numeric = transformer.session_numeric_np(numerics[i], mem_slice_numerics)\n",
    "            \n",
    "            if mem_frame is None or mem_numeric is None:\n",
    "                continue\n",
    "            \n",
    "            np.save(val_path + GenFiles.frame.format(memory_string, stored_i + existing_count), mem_frame)\n",
    "            np.save(val_path + GenFiles.numeric.format(memory_string, stored_i + existing_count), mem_numeric)\n",
    "            np.save(val_path + GenFiles.diff.format(memory_string, stored_i + existing_count), diffs[i])\n",
    "            stored_i += 1\n",
    "            \n",
    "        gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate sampling files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NB this is shifted steering + throttle specific\n",
    "samplings = {}\n",
    "\n",
    "for memory_string, total_diff in total_diffs.items():    \n",
    "    sampling = np.ones(total_diff.shape[0])\n",
    "    #sampling = downsample_indexes(total_diff[:, 2], half_max_thresh, bin_start=0.0)\n",
    "    #sampling = downsample_indexes(total_diff[:, 1], half_max_thresh, sampling=sampling)\n",
    "    #sampling = downsample_indexes(total_diff[:, 1], double_mean_thresh)\n",
    "    #sampling = downsample_indexes(total_diff[:, 1], mean_thresh)\n",
    "    sampling = sample_recovery_indexes(total_diff[:, 0], sampling=sampling)\n",
    "    #sampling = upsample_indexes(total_diff[:, 1], sampling, half_max_thresh)\n",
    "    #sampling = upsample_indexes(total_diff[:, 1], sampling, double_mean_thresh)\n",
    "    #sampling = upsample_indexes(total_diff[:, 2], sampling, mean_thresh)\n",
    "    sampling = upsample_indexes(total_diff[:, 1], sampling, mean_thresh)\n",
    "    \n",
    "    samplings[memory_string] = sampling\n",
    "    sample_path = base_path + memory_string + '/'\n",
    "    store_sampling(sampling, sample_path, GenFiles.steer_sampling.format(memory_string), clean=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NB this is shifted gear specific\n",
    "gear_samplings = {}\n",
    "\n",
    "for memory_string, total_diff in total_diffs.items():\n",
    "    gear_sampling = np.ones(total_diff.shape[0])\n",
    "    gear_sampling = downsample_indexes(total_diff[:, 0], mean_thresh, bin_start=-1, bin_end=2, bin_size=1)\n",
    "    gear_sampling = upsample_indexes(total_diff[:, 0], gear_sampling, mean_thresh, bin_start=-1, bin_end=2, bin_size=1)\n",
    "    \n",
    "    gear_samplings[memory_string] = sampling\n",
    "    sample_path = base_path + memory_string + '/'\n",
    "    store_sampling(gear_sampling, sample_path, GenFiles.gear_sampling.format(memory_string), clean=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analyse sampling effects, compared to original distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "memory_string = 'n1_m1'\n",
    "path = base_path + memory_string + '/'\n",
    "\n",
    "diffs = total_diffs[memory_string]\n",
    "sampling = samplings[memory_string]\n",
    "#gear_sampling = gear_samplings[memory_string]\n",
    "\n",
    "print(len([fn for fn in os.listdir(path) if fn.startswith('frame_')]))\n",
    "print(len([fn for fn in os.listdir(path) if fn.startswith('numeric_')]))\n",
    "print(len([fn for fn in os.listdir(path) if fn.startswith('diff_')]))\n",
    "print(diffs.shape)\n",
    "print(sampling.shape)\n",
    "#print(gear_sampling.shape)\n",
    "\n",
    "sampled_diffs = np.repeat(diffs, sampling, axis=0)\n",
    "#gear_diffs = np.repeat(diffs, gear_sampling, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_elems = []\n",
    "plot_elems.append({'data': diffs[:, 1], 'kwargs':{'label': 'Raw steering', 'alpha': 0.9}})\n",
    "bins = np.arange(-1.0, 1.01, 0.01)\n",
    "plot_stuff('Steering', plot_elems, bins)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.patheffects as pe\n",
    "\n",
    "plot_elems = []\n",
    "plot_elems.append({'data': diffs[:, 1], 'kwargs':{'label': 'Raw steering', 'alpha': 0.9, 'color':'k'}})\n",
    "plot_elems.append({'data': sampled_diffs[:, 1], 'kwargs':{'label': 'Sampled steering', 'alpha': 0.5, 'color':'w', 'path_effects':[pe.Stroke(linewidth=1, foreground='k'), pe.Normal()]}})\n",
    "plot_elems.append({'data': [], 'kwargs':{'label': 'Overlap', 'color':'#808080'}})\n",
    "bins = np.arange(-1.0, 1.01, 0.01)\n",
    "plot_stuff('Steering', plot_elems, bins)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_elems = []\n",
    "plot_elems.append({'data': diffs[:, 2], 'kwargs':{'label': 'Raw throttle', 'alpha': 0.9}})\n",
    "bins = np.arange(0.0, 1.01, 0.01)\n",
    "plot_stuff('Throttle', plot_elems, bins)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_elems = []\n",
    "plot_elems.append({'data': diffs[:, 2], 'kwargs':{'label': 'Raw throttle', 'alpha': 0.9, 'color':'k'}})\n",
    "plot_elems.append({'data': sampled_diffs[:, 2], 'kwargs':{'label': 'Sampled throttle', 'alpha': 0.5, 'color':'w', 'path_effects':[pe.Stroke(linewidth=1, foreground='k'), pe.Normal()]}})\n",
    "plot_elems.append({'data': [], 'kwargs':{'label': 'Overlap', 'color':'#808080'}})\n",
    "bins = np.arange(0.0, 1.01, 0.01)\n",
    "plot_stuff('Throttle', plot_elems, bins)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_elems = []\n",
    "plot_elems.append({'data': diffs[:, 0], 'label': 'gear', 'alpha': 0.9})\n",
    "#plot_elems.append({'data': gear_diffs[:, 0], 'label': 'sampled gear', 'alpha': 0.6})\n",
    "bins = np.arange(-1, 1.2, 0.1)\n",
    "plot_stuff('gear', plot_elems, bins)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
