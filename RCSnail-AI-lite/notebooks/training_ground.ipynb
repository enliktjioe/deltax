{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import os\n",
    "import sys\n",
    "import gc\n",
    "import time\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.utils import plot_model\n",
    "\n",
    "module_path_list = [os.path.abspath(os.path.join('../')), \n",
    "                    os.path.abspath(os.path.join('../../RCSnail-Commons'))]\n",
    "for module_path in module_path_list:\n",
    "    if module_path not in sys.path:\n",
    "        sys.path.append(module_path)\n",
    "\n",
    "from commons.configuration_manager import ConfigurationManager\n",
    "#from src.utilities.transformer import Transformer\n",
    "from src.learning.training.generator import Generator, GenFiles\n",
    "# from src.learning.models import create_standalone_nvidia_cnn, create_standalone_resnet, create_small_cnn\n",
    "from src.learning.models import create_standalone_nvidia_cnn, create_standalone_resnet\n",
    "                                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_stuff(title, plot_elem, figsize=(18, 10)):\n",
    "    fig=plt.figure(figsize=figsize)\n",
    "    plt.title(title)\n",
    "    plt.ylabel('Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    #x = np.arange(0, len(plot_elems[0]['data']), 1)\n",
    "    \n",
    "    #for plot_elem in plot_elems:\n",
    "    #    plt.errorbar(x, plot_elem['data'], yerr=plot_elem['error'], label=plot_elem['label'], alpha=plot_elem['alpha'], fmt='-o', capsize=5)\n",
    "    \n",
    "    plt.plot(list(range(1,len(plot_elem['data'])+1)), plot_elem['data'])\n",
    "    plt.grid(axis='both')\n",
    "    #plt.legend(loc='best', prop={'size': 15})\n",
    "    plt.show()\n",
    "    plt.savefig('./' + title + '.png')\n",
    "    \n",
    "def get_model_num(model_path, model_prefix):\n",
    "    model_files = [fn for fn in os.listdir(model_path) if fn.startswith(model_prefix) and fn.endswith('.h5') and 'dagger_' not in fn]\n",
    "    # expected format is \"model_n1_m1_9.h5\"\n",
    "    existing_nums = [int(fn.split('_')[3].split('.')[0]) for fn in model_files]\n",
    "    \n",
    "    if len(existing_nums) == 0:\n",
    "        return 1\n",
    "    else:\n",
    "        latest_num = sorted(existing_nums)[-1]\n",
    "        return int(latest_num) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "config_manager = ConfigurationManager()\n",
    "config = config_manager.config\n",
    "\n",
    "memory = (1, 1)\n",
    "#ARDI' comment -- we just use (1,1) this refers to how many frames are used and sth else, not sure what\n",
    "\n",
    "model_path = '../'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Target shape: 2\n",
      "Input shapes: (60, 180, 3)\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "def scheduler(epoch, lr):\n",
    "    if epoch>30 and epoch%10==0:\n",
    "        lr*=0.5\n",
    "    return lr\n",
    "\n",
    "\n",
    "# Model experiments\n",
    "import os\n",
    "\n",
    "epochs = 50\n",
    "batch_size = 64\n",
    "verbose = 1\n",
    "\n",
    "losses = []\n",
    "val_losses = []\n",
    "\n",
    "#in here added option to not shuffle, so last 20% of recording time is used as val set -- in future might want to reduce proportion of val set\n",
    "generator = Generator(config, memory_tuple= memory, base_path='../', batch_size=batch_size, column_mode='all', shuffle_data=False) \n",
    "\n",
    "# frame_shape, numeric_shape, diff_shape = generator.get_shapes()\n",
    "frame_shape, diff_shape = generator.get_shapes()\n",
    "\n",
    "tqdm.write('Target shape: {}'.format(diff_shape)) #tqdm is some package that allow to track the progress of operations\n",
    "tqdm.write('Input shapes: {}'.format(frame_shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cabe31c14202400ab67bf8c19ea03be2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n1_m1\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "ename": "InvalidArgumentError",
     "evalue": " Input to reshape is a tensor with 753664 values, but the requested shape requires a multiple of 10304\n\t [[node model/flatten/Reshape (defined at <ipython-input-6-a03261c5b9b9>:22) ]] [Op:__inference_train_function_1444]\n\nFunction call stack:\ntrain_function\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-a03261c5b9b9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     20\u001b[0m                      \u001b[0mvalidation_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgenerator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtest_batch_count\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m                      \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m                      epochs=epochs, verbose=verbose)\n\u001b[0m\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m     \u001b[0mmodel_file_prefix\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'model_n{}_m{}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mmemory\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1098\u001b[0m                 _r=1):\n\u001b[1;32m   1099\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1100\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1101\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1102\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    826\u001b[0m     \u001b[0mtracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    827\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtrace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtm\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 828\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    829\u001b[0m       \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"xla\"\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_experimental_compile\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    830\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    886\u001b[0m         \u001b[0;31m# Lifting succeeded, so variables are initialized and we can run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    887\u001b[0m         \u001b[0;31m# stateless function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 888\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    889\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    890\u001b[0m       \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfiltered_flat_args\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2941\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m   2942\u001b[0m     return graph_function._call_flat(\n\u001b[0;32m-> 2943\u001b[0;31m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m   2944\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2945\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1917\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1918\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1919\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1920\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1921\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    558\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    559\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 560\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    561\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    562\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[0;32m~/miniconda3/lib/python3.7/site-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 60\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m:  Input to reshape is a tensor with 753664 values, but the requested shape requires a multiple of 10304\n\t [[node model/flatten/Reshape (defined at <ipython-input-6-a03261c5b9b9>:22) ]] [Op:__inference_train_function_1444]\n\nFunction call stack:\ntrain_function\n"
     ]
    }
   ],
   "source": [
    "models = []\n",
    "\n",
    "# ARDI's comment:  Nividia is the model we want to use (resnet might be good to??)\n",
    "generator = Generator(config, memory_tuple= memory, base_path='../', batch_size=batch_size, column_mode='all', shuffle_data=True)\n",
    "models.append((create_standalone_nvidia_cnn(activation='linear', input_shape=(50, 180, 3), output_shape=2), generator.generate))\n",
    "\n",
    "# # \"steer and throttle\"\n",
    "# generator = Generator(config, memory_tuple= memory, base_path='../', batch_size=batch_size, column_mode='all', shuffle_data=False) \n",
    "# models.append((create_small_cnn(activation='linear', input_shape=(50, 180, 3), output_shape=2), generator.generate))\n",
    "\n",
    "callbacks=[tf.keras.callbacks.LearningRateScheduler(scheduler)]\n",
    "\n",
    "for model, generate_method in tqdm(models):\n",
    "    result_desc = 'n{}_m{}'.format(*memory)\n",
    "    tqdm.write(result_desc)\n",
    "\n",
    "    hist = model.fit(generate_method(data='train'),\n",
    "                     steps_per_epoch=generator.train_batch_count,\n",
    "                     validation_data=generate_method(data='test'),\n",
    "                     validation_steps=generator.test_batch_count,\n",
    "                     callbacks=callbacks,\n",
    "                     epochs=epochs, verbose=verbose)\n",
    "\n",
    "    model_file_prefix = 'model_n{}_m{}'.format(*memory)\n",
    "    model_file_suffix = '_{}.{}'\n",
    "\n",
    "    model_number = get_model_num(model_path, model_file_prefix)\n",
    "    plot_model(model, to_file=model_path + model_file_prefix + model_file_suffix.format(model_number, 'png'), show_shapes=True)\n",
    "    model.save(model_path + model_file_prefix + model_file_suffix.format(model_number, 'h5'))\n",
    "    \n",
    "    current_loss = hist.history['loss']\n",
    "    current_val_loss = hist.history['val_loss'] \n",
    "    \n",
    "    losses.append(current_loss)\n",
    "    print(val_losses)\n",
    "    val_losses.append(current_val_loss)\n",
    "    \n",
    "    tqdm.write(\"Loss per epoch: {}\".format(current_loss))\n",
    "    tqdm.write(\"Validation loss per epoch: {}\".format(current_val_loss))\n",
    "    \n",
    "    gc.collect()\\\n",
    "\n",
    "\n",
    "os.system(\"printf '\\a'\")\\"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(val_losses)\n",
    "print(hist.history['val_loss'] )\n",
    "loss_data = []\n",
    "val_loss_data = []\n",
    "\n",
    "\n",
    "val_loss_data = {'data': hist.history['val_loss'], 'label': 'Validation loss', 'alpha': 1.0}\n",
    "plot_stuff('Nivida cnn standalone validation loss', val_loss_data, figsize=(10, 6))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_data = {'data': losses[0], 'label': 'Loss', 'alpha': 1.0}\n",
    "plot_stuff('Training', loss_data, figsize=(10, 6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#todo load test set into memeory, evaluate\n",
    "import keras\n",
    "model = keras.models.load_model(\"../masked_test.h5\")\n",
    "import glob\n",
    "\n",
    "val_data_loc=\"../n1_m1\"\n",
    "filenames = glob.glob(\"../n1_m1/*\")\n",
    "print(len(filenames))\n",
    "nr_of_datapoints = int(len(filenames)/2) #label and image files\n",
    "\n",
    "\n",
    "MAEs=[]\n",
    "preds=[]\n",
    "labels=[]\n",
    "\n",
    "for batch in range(nr_of_datapoints//32-32,nr_of_datapoints//32): # using the end of file. 32 batches of size batch of 32\n",
    "    frames=np.zeros((32,50,180,3))\n",
    "    commands = np.zeros((32,2))\n",
    "    for i in range(32):\n",
    "        frames[i,:] = np.load(\"../n1_m1/frame_\"+str(batch*32+i).zfill(7)+\".npy\")\n",
    "        commands[i] = np.load(\"../n1_m1/commands_\"+str(batch*32+i).zfill(7)+\".npy\")\n",
    "    MAEs.append(model.evaluate(frames,commands, batch_size=32))\n",
    "    pred = model.predict(frames)\n",
    "    preds.append(pred)\n",
    "    labels.append(commands)\n",
    "    \n",
    "print(np.mean(MAEs))\n",
    "#TODO MAE for steer and throttle separately, mased on preds and commands"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.mean(MAEs))\n",
    "p_steer=np.array(preds)[:,:,0]\n",
    "l_steer=np.array(labels)[:,:,0]\n",
    "p_throttle=np.array(preds)[:,:,1]\n",
    "l_throttle=np.array(labels)[:,:,1]\n",
    "\n",
    "print(p_steer.shape,l_steer.shape)\n",
    "p_steer=p_steer.flatten()\n",
    "l_steer=l_steer.flatten()\n",
    "p_throttle=p_throttle.flatten()\n",
    "l_throttle=l_throttle.flatten()\n",
    "\n",
    "\n",
    "plt.figure(figsize=(32,8))\n",
    "plt.plot(range(1000),l_steer[:1000],label=\"human steering\")\n",
    "plt.plot(range(1000),p_steer[:1000],label=\"predicted\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "plt.figure(figsize=(32,8))\n",
    "plt.plot(range(1000),l_throttle[:1000],label=\"human throttle\")\n",
    "plt.plot(range(1000),p_throttle[:1000],label=\"predicted\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n",
    "plt.scatter(l_steer,p_steer,s=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
